# Challenge-TelecomX_PT2

# :computer: Projeto de Modelagem Preditiva com KNN e Random Forest Regressor 
Este projeto de machine learning visa a criaÃ§Ã£o e comparaÃ§Ã£o de modelos de regressÃ£o para realizar previsÃµes precisas. Utilizando Python, exploramos a performance de dois algoritmos populares: K-Nearest Neighbors (KNN) e Random Forest Regressor, para determinar qual deles oferece o melhor desempenho para a tarefa de modelagem.

# âš™ï¸Tecnologias Utilizadas âš™
O projeto foi desenvolvido inteiramente em Python, aproveitando o ecossistema de bibliotecas de Data Science e Machine Learning para a manipulaÃ§Ã£o, visualizaÃ§Ã£o de dados e construÃ§Ã£o dos modelos.


Linguagem de ProgramaÃ§Ã£o: Python 
<img src="https://raw.githubusercontent.com/marwin1991/profile-technology-icons/refs/heads/main/icons/python.png" alt="Python" width="30" height="50"/>


Bibliotecas: 

Pandas: <img src="imagens/pandas.svg" width="30" height="50">

NumPy: <img src="https://raw.githubusercontent.com/marwin1991/profile-technology-icons/refs/heads/main/icons/numpy.png" alt="NumPy:" width="30" height="50"/> 

Scikit-learn: <img src="imagens/scikit-learn.png" width="60" height="80">

Matplotlib: <img src="imagens/Matplotlib.png" width="40" height="60">

Seaborn: <img src="https://upload.wikimedia.org/wikipedia/commons/4/45/Logo-seaborn.png" alt="Python" width="40" height="60"/>

# ğŸ¯   Objetivo do Projeto 

ğŸ§  Algoritmos Implementados
O cerne deste projeto Ã© a implementaÃ§Ã£o e comparaÃ§Ã£o de dois modelos de regressÃ£o.

K-Nearest Neighbors (KNN) Regressor: Um algoritmo de aprendizado supervisionado nÃ£o paramÃ©trico que faz previsÃµes com base nos vizinhos mais prÃ³ximos.

Random Forest Regressor: Um algoritmo de aprendizado supervisionado que constrÃ³i uma "floresta" de Ã¡rvores de decisÃ£o aleatÃ³rias para fazer previsÃµes mais robustas e precisas.

# ğŸ“Š Resultados e AnÃ¡lise
Ambos os modelos foram avaliados usando mÃ©tricas de desempenho comuns para regressÃ£o, como o RÂ² (coeficiente de determinaÃ§Ã£o), que mede a proporÃ§Ã£o da variÃ¢ncia na variÃ¡vel dependente que Ã© previsÃ­vel a partir das variÃ¡veis independentes.

ApÃ³s a anÃ¡lise, o Random Forest Regressor demonstrou um desempenho superior, com um RÂ² de 0.98, superando o KNN Regressor, que obteve um RÂ² de 0.94.

Isso indica que o modelo de Random Forest conseguiu capturar melhor a complexidade e as relaÃ§Ãµes nos dados, resultando em previsÃµes mais acuradas.

# ğŸš€ Como Rodar o Projeto
Para replicar a anÃ¡lise e os modelos localmente, siga os passos abaixo.

:loudspeaker:VocÃª pode seguir os passos no notebook Python ([TelecomX_parte2_BR] (https://github.com/LipeSilva83/TelecomX_parte2_BR)). Certifique-se de ter as bibliotecas necessÃ¡rias instaladas (pandas, matplotlib, seaborn).


# âœ’ï¸ Autor
[Filipe Silva] - [https://github.com/LipeSilva83]

# ğŸ“œ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT License. Para mais detalhes, veja o arquivo LICENSE.

